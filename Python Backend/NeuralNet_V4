import numpy as np
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from sklearn.model_selection import ParameterGrid
from dataV2 import get_processed_data

# Create the network

class Net(nn.Module):
    def __init__(self, nbr_layers, neurons_per_layers, input_features, num_classes):
        super(Net, self).__init__()
        self.network = nn.ModuleList()
        self.network.append(nn.Linear(input_features, neurons_per_layers))
        for _ in range(nbr_layers - 1):
            self.network.append(nn.Linear(neurons_per_layers, neurons_per_layers))
        self.network.append(nn.Linear(neurons_per_layers, num_classes))
    
    def forward(self, x):
        for layer in self.network:
            x = F.leaky_relu(layer(x))
        return x

# create the optimizer

def create_optimizer(lr, net):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(net.parameters(), lr=lr)

    return criterion, optimizer


def train(X_train, y_train, nbr_layers, neurons_per_layers, lr):
    # Convert data to tensors
    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
    y_train_tensor = torch.tensor(y_train, dtype=torch.int64) - 1  # Ensure zero-indexed labels
    
    # Automatically determine the number of unique classes for the output layer
    num_classes = len(torch.unique(y_train_tensor))
    input_features = X_train.shape[1]
    
    # Initialize the network and optimizer
    net = Net(nbr_layers, neurons_per_layers, input_features, num_classes)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(net.parameters(), lr=lr)
    
    losses = []
    for epoch in range(1000):  # loop over the dataset multiple times
        optimizer.zero_grad()
        
        # forward + backward + optimize
        outputs = net(X_train_tensor)
        loss = criterion(outputs, y_train_tensor)
        loss.backward()
        optimizer.step()

        # print statistics
        losses.append(loss.item())

        if epoch % 100 == 99:  # print every 100 epochs
            print(f'Epoch {epoch + 1}, Loss: {loss.item()}')
    
    print('Finished Training')
    return net, losses

def calculate_accuracy(model, X_val, y_val):
    # Convert validation data to tensors
    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)
    y_val_tensor = torch.tensor(y_val, dtype=torch.int64) - 1  # Ensure zero-indexed labels if necessary

    # Forward pass to get output/logits
    outputs = model(X_val_tensor)

    # Get predictions from the maximum value
    _, predicted = torch.max(outputs, 1)

    # Total number of labels
    total = y_val_tensor.size(0)

    # Total correct predictions
    correct = (predicted == y_val_tensor).sum().item()

    accuracy = correct / total
    return accuracy

if __name__ == "__main__":

    X_train, X_val, y_train, y_val = get_processed_data() 
    nbr_layers = 2
    neurons_per_layers = 64
    lr = 0.001

    trained_net, training_losses = train(X_train, y_train, nbr_layers, neurons_per_layers, lr)
    # print (trained_net)
    # # print (training_losses)
    # accuracy = calculate_accuracy(trained_net, X_val, y_val)
    # print(f'Accuracy of the network on the validation set: {accuracy * 100:.2f}%')

    # Define a grid of hyperparameters
param_grid = {
    'nbr_layers': [2, 3, 5], 
    'neurons_per_layer': [256, 64, 128, 150]  
}

# Create a parameter grid
grid = ParameterGrid(param_grid)

# Placeholder fValues
best_accuracy = 0
best_model = None
best_params = {}

# Iterate over all combinations
for params in grid:
    print(f"Training with params: {params}")
    trained_net, _ = train(X_train, y_train, params['nbr_layers'], params['neurons_per_layer'], lr=0.001)
    accuracy = calculate_accuracy(trained_net, X_val, y_val)
    print(f"Accuracy: {accuracy * 100:.2f}%")

    # Update the best model if current model is better
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_model = trained_net
        best_params = params

    print(f"Best Parameters: {best_params}")
    print(f"Best Accuracy: {best_accuracy * 100:.2f}%")
